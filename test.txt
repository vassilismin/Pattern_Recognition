
Μία διαφορετική διατύπωση του νόμου του \en Bayes \gr είναι εκείνη η οποία ορίζει ως $\theta$ μία παράμετρο ή ένα διάνυσμα παραμέτρων και $y$ τα δεδομένα που σχετίζονται με το παραμετρικό διάνυσμα $\theta$. Κατά συνέπεια, ως $P(\theta)$ και $P(y)$ ορίζονται οι κατανομές των $\theta$ και $y$ αντίστοιχα. Η $P(\theta)$ συχνά αναφέρεται ως εκ των προτέρων κατανομή (\en prior distribution) \gr ενώ η $P(y|\theta)$ ως πιθανοφάνεια (\en likelihood). \gr Η από κοινού κατανομή (\en joint probability) \gr των $\theta$ και $y$ συμβολίζεται ως $P(\theta,y)$ και ισούται με:
\begin{equation}
    \label{joint_prob}
    P(\theta,y)=P(\theta) \cdot P(y|\theta).
\end{equation}
Συνεπώς, εφαρμόζοντας τα παραπάνω στη σχέση (\ref{Bayes}) προκύπτει ότι η εκ των υστέρων κατανομή $P(\theta|y)$ (\en posterior distribution) \gr υπολογίζεται ως εξής:
\begin{equation}
    \label{posterior}
    P(\theta|y) = \frac{P(\theta,y)}{P(y)}= \frac{P(\theta) \cdot P(y|\theta)}{P(y)}.
\end{equation}
Στην εξίσωση (\ref{posterior}), η $P(y)$ ισούται με $P(y)=\sum_{\theta} P(\theta)P(y|\theta)$, όπου το άθροισμα γίνεται πάνω σε όλες τις πιθανές τιμές του $\theta$ (στην περίπτωση που το $\theta$ αναφέρεται σε συνεχείς μεταβλητές τότε ισχύει $P(y)=\int{P(\theta)P(y|\theta)d\theta}$). Λαμβάνοντας υπόψιν ότι το $y$ παραμένει σταθερό και ότι η $P(y)$ είναι ανεξάρτητη του $\theta$, μπορούμε να παραλείψουμε τον όρο $P(y)$ από τη σχέση (\ref{posterior}) και να καταλήξουμε στην ισοδύναμη σχέση (\ref{unnormalized_post}) που δίνει την μη κανονικοποιημένη εκ των υστέρων κατανομή (\en unnormalized posterior distribution):
\begin{equation}
    \label{unnormalized_post}
    P(\theta|y) \propto P(\theta) \cdot P(y|\theta).
\end{equation}
